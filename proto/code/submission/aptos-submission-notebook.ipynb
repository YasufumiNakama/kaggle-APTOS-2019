{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "from functools import partial\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import numbers\n",
    "\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as M\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import (Compose, ToTensor, Normalize, Resize, RandomHorizontalFlip)\n",
    "\n",
    "sub = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n",
    "folds = pd.read_csv(\"../input/aptos-folds/folds.csv\")\n",
    "N_CLASSES = 1\n",
    "\n",
    "##################### quadratic_weighted_kappa ########################\n",
    "def quadratic_weighted_kappa(y_hat, y):\n",
    "    return cohen_kappa_score(y_hat, y, weights='quadratic')\n",
    "\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "\n",
    "##################### DataSet ########################\n",
    "def load_image(path, item):\n",
    "    image = cv2.imread(f'{path}/{item}.png')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(image)\n",
    "\n",
    "class TTADataset(Dataset):\n",
    "    def __init__(self, root, ids, tta=4):\n",
    "        self.root = root\n",
    "        self.ids = ids\n",
    "        \n",
    "        self.transform = Compose([\n",
    "            Resize((256, 256)),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "            \n",
    "        self.tta = tta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids) * self.tta\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_id = self.ids[idx % len(self.ids)]\n",
    "        image = load_image(self.root, item_id)\n",
    "        image = self.transform(image)\n",
    "        return image, item_id\n",
    "\n",
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, root, df):\n",
    "        super().__init__()\n",
    "        self._root = root\n",
    "        self._df = df\n",
    "        \n",
    "        self.transform = Compose([\n",
    "            Resize((256, 256)),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        item = self._df.iloc[idx]\n",
    "        image = load_image(self._root, item.id_code)\n",
    "        image = self.transform(image)\n",
    "        target = torch.tensor(self._df.loc[idx, 'diagnosis'])\n",
    "        return image, target\n",
    "    \n",
    "##################### Models ########################\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "    \n",
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, weights_path, net_cls=M.resnet101):\n",
    "        super().__init__()\n",
    "        self.net = net_cls()\n",
    "        self.net.avgpool = AvgPool()\n",
    "        self.net.fc = nn.Linear(self.net.fc.in_features, N_CLASSES)\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.fc.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, weights_path, net_cls=M.densenet121):\n",
    "        super().__init__()\n",
    "        self.net = net_cls()\n",
    "        self.avg_pool = AvgPool()\n",
    "        self.net.classifier = nn.Linear(self.net.classifier.in_features, N_CLASSES)\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.classifier.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net.features(x)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        out = self.avg_pool(out).view(out.size(0), -1)\n",
    "        out = self.net.classifier(out)\n",
    "        return out\n",
    "    \n",
    "class InceptionNet(nn.Module):\n",
    "    def __init__(self, weights_path, net_cls=M.inception_v3):\n",
    "        super().__init__()\n",
    "        self.net = net_cls()\n",
    "        self.net.fc = nn.Linear(self.net.fc.in_features, N_CLASSES)\n",
    "        self.net.AuxLogits.fc = nn.Linear(self.net.AuxLogits.fc.in_features, N_CLASSES)\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.fc.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "resnet18 = partial(ResNet, net_cls=M.resnet18)\n",
    "resnet34 = partial(ResNet, net_cls=M.resnet34)\n",
    "resnet50 = partial(ResNet, net_cls=M.resnet50)\n",
    "resnet101 = partial(ResNet, net_cls=M.resnet101)\n",
    "resnet152 = partial(ResNet, net_cls=M.resnet152)\n",
    "\n",
    "#densenet121 = partial(DenseNet, net_cls=M.densenet121)\n",
    "#densenet169 = partial(DenseNet, net_cls=M.densenet169)\n",
    "#densenet201 = partial(DenseNet, net_cls=M.densenet201)\n",
    "#densenet161 = partial(DenseNet, net_cls=M.densenet161)\n",
    "\n",
    "class SEResNet50(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNetBottleneck, [3,4,6,3], groups=1, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SEResNet101(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNetBottleneck, [3,4,23,3], groups=1, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SEResNet152(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNetBottleneck, [3,8,36,3], groups=1, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SEResNeXt50_32x4d(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNeXtBottleneck, [3,4,6,3], groups=32, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SEResNeXt101_32x4d(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNeXtBottleneck, [3,4,23,3], groups=32, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "se_resnet50 = partial(SEResNet50, net_cls=None)\n",
    "se_resnet101 = partial(SEResNet101, net_cls=None)\n",
    "se_resnet152 = partial(SEResNet152, net_cls=None)\n",
    "se_resnext50_32x4d = partial(SEResNeXt50_32x4d, net_cls=None)\n",
    "se_resnext101_32x4d = partial(SEResNeXt101_32x4d, net_cls=None)\n",
    "\n",
    "##################### Prediction ########################\n",
    "def predictoin(model, df, mode=\"test\"):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    if mode==\"test\":\n",
    "        test_dataset = TTADataset('../input/aptos2019-blindness-detection/test_images', df.id_code.values, tta=2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "        all_predictions, all_ids = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, ids in test_loader:\n",
    "                all_ids.append(ids)\n",
    "                device = \"cuda:0\"\n",
    "                inputs = inputs.to(device, dtype=torch.float)\n",
    "                predictions = model(inputs)\n",
    "                all_predictions.append(predictions.cpu().numpy())\n",
    "        all_predictions = np.concatenate(all_predictions)\n",
    "        all_ids = np.concatenate(all_ids)\n",
    "        test_preds = pd.DataFrame(data=all_predictions,\n",
    "                                  index=all_ids,\n",
    "                                  columns=map(str, range(N_CLASSES)))\n",
    "        test_preds = test_preds.groupby(level=0).mean()\n",
    "        return test_preds\n",
    "        \n",
    "    else:\n",
    "        test_dataset = ValidDataset('../input/aptos2019-blindness-detection/train_images', df)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "        all_predictions, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                all_targets.append(targets.numpy().copy())\n",
    "                device = \"cuda:0\"\n",
    "                inputs = inputs.to(device, dtype=torch.float)\n",
    "                predictions = model(inputs)\n",
    "                all_predictions.append(predictions.cpu().numpy())\n",
    "        all_predictions = np.concatenate(all_predictions)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        \n",
    "        optR = OptimizedRounder()\n",
    "        optR.fit(all_predictions, all_targets)\n",
    "        coefficients = optR.coefficients()\n",
    "        y_pred = optR.predict(all_predictions, coefficients)\n",
    "\n",
    "        def get_score(y_pred):\n",
    "            return quadratic_weighted_kappa(all_targets, y_pred)\n",
    "        \n",
    "        qwk = get_score(y_pred)\n",
    "        #print(\"QWK: \", qwk)\n",
    "        return coefficients\n",
    "\n",
    "    del model, test_dataset, test_loader\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################### main ########################\n",
    "def main():\n",
    "    valid_fold = folds[folds['fold'] == 0].reset_index(drop=True)\n",
    "    model = se_resnext101_32x4d('../input/aptos-weights1/se_resnext101_256_v42_fold0.pth')\n",
    "    coefficients = predictoin(model=model, df=valid_fold, mode=\"valid\")\n",
    "    test_preds = predictoin(model=model, df=sub, mode=\"test\")\n",
    "    optR = OptimizedRounder()\n",
    "    y_pred = optR.predict(test_preds, coefficients)\n",
    "    sub['diagnosis'] = y_pred.astype(int)\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
